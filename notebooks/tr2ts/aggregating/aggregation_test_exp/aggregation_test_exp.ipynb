{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, BooleanType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID_BIC_CLIENTE: integer (nullable = false)\n",
      " |-- DATA_TRANSAZIONE: timestamp (nullable = true)\n",
      " |-- IMPORTO: float (nullable = false)\n",
      " |-- CA_CATEGORY_LIV0: string (nullable = false)\n",
      " |-- IS_CARTA: boolean (nullable = false)\n",
      " |-- bucket: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      "\n",
      "+--------------+-------------------+-------+----------------+--------+------------------------------------------+\n",
      "|ID_BIC_CLIENTE|DATA_TRANSAZIONE   |IMPORTO|CA_CATEGORY_LIV0|IS_CARTA|bucket                                    |\n",
      "+--------------+-------------------+-------+----------------+--------+------------------------------------------+\n",
      "|348272371     |2023-01-01 00:00:00|5.5    |shopping        |true    |{2023-01-01 00:00:00, 2023-01-02 00:00:00}|\n",
      "|348272371     |2023-01-01 00:00:00|6.1    |salute          |false   |{2023-01-01 00:00:00, 2023-01-02 00:00:00}|\n",
      "|348272371     |2023-01-01 00:00:00|8.2    |trasporti       |false   |{2023-01-01 00:00:00, 2023-01-02 00:00:00}|\n",
      "|348272371     |2023-01-01 00:00:00|1.5    |trasporti       |true    |{2023-01-01 00:00:00, 2023-01-02 00:00:00}|\n",
      "|348272371     |2023-01-06 00:00:00|20.2   |shopping        |false   |{2023-01-06 00:00:00, 2023-01-07 00:00:00}|\n",
      "|348272371     |2023-01-06 00:00:00|43.0   |shopping        |true    |{2023-01-06 00:00:00, 2023-01-07 00:00:00}|\n",
      "|348272371     |2023-01-06 00:00:00|72.2   |shopping        |false   |{2023-01-06 00:00:00, 2023-01-07 00:00:00}|\n",
      "|234984832     |2023-01-01 00:00:00|15.34  |salute          |true    |{2023-01-01 00:00:00, 2023-01-02 00:00:00}|\n",
      "|234984832     |2023-01-01 00:00:00|36.22  |salute          |true    |{2023-01-01 00:00:00, 2023-01-02 00:00:00}|\n",
      "|234984832     |2023-01-01 00:00:00|78.35  |salute          |false   |{2023-01-01 00:00:00, 2023-01-02 00:00:00}|\n",
      "|234984832     |2023-01-02 00:00:00|2.2    |trasporti       |true    |{2023-01-02 00:00:00, 2023-01-03 00:00:00}|\n",
      "+--------------+-------------------+-------+----------------+--------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (348272371, \"2023-01-01\", 5.50, \"shopping\", True, (\"2023-01-01\", \"2023-01-02\")),\n",
    "        (348272371, \"2023-01-01\", 6.10, \"salute\", False, (\"2023-01-01\", \"2023-01-02\")),\n",
    "        (348272371, \"2023-01-01\", 8.20, \"trasporti\", False, (\"2023-01-01\", \"2023-01-02\")),\n",
    "        (348272371, \"2023-01-01\", 1.50, \"trasporti\", True, (\"2023-01-01\", \"2023-01-02\")),\n",
    "        (348272371, \"2023-01-06\", 20.20, \"shopping\", False, (\"2023-01-06\", \"2023-01-07\")),\n",
    "        (348272371, \"2023-01-06\", 43.00, \"shopping\", True, (\"2023-01-06\", \"2023-01-07\")),\n",
    "        (348272371, \"2023-01-06\", 72.20, \"shopping\", False, (\"2023-01-06\", \"2023-01-07\")),\n",
    "        (234984832, \"2023-01-01\", 15.34, \"salute\", True, (\"2023-01-01\", \"2023-01-02\")),\n",
    "        (234984832, \"2023-01-01\", 36.22, \"salute\", True, (\"2023-01-01\", \"2023-01-02\")),\n",
    "        (234984832, \"2023-01-01\", 78.35, \"salute\", False, (\"2023-01-01\", \"2023-01-02\")),\n",
    "        (234984832, \"2023-01-02\", 2.20, \"trasporti\", True, (\"2023-01-02\", \"2023-01-03\")),\n",
    "    ],\n",
    "    schema=StructType([\n",
    "        StructField(\"ID_BIC_CLIENTE\", IntegerType(), False),\n",
    "        StructField(\"DATA_TRANSAZIONE\", StringType(), False),\n",
    "        StructField(\"IMPORTO\", FloatType(), False),\n",
    "        StructField(\"CA_CATEGORY_LIV0\", StringType(), False),\n",
    "        StructField(\"IS_CARTA\", BooleanType(), False),\n",
    "        StructField(\"bucket\", StructType([\n",
    "            StructField(\"start\", StringType(), False),\n",
    "            StructField(\"end\", StringType(), False),\n",
    "        ]), False)\n",
    "    ])\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"DATA_TRANSAZIONE\", F.to_timestamp(F.col(\"DATA_TRANSAZIONE\"), \"yyyy-MM-dd\"))\n",
    "df = df.withColumn(\"bucket\", F.struct(\n",
    "        F.to_timestamp(F.col(\"bucket.start\"), \"yyyy-MM-dd\").alias(\"start\"),\n",
    "        F.to_timestamp(F.col(\"bucket.end\"), \"yyyy-MM-dd\").alias(\"end\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
