{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from enum import Enum\n",
    "\n",
    "from pydantic import BaseModel, conlist, StrictStr, StrictBool, StrictInt, StrictFloat, model_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericOperator(str, Enum):\n",
    "    EQUAL = \"=\"\n",
    "    DOUBLEEQUAL = \"==\"\n",
    "    NOTEQUAL = \"!=\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._value_\n",
    "\n",
    "\n",
    "class NumericalOperator(str, Enum):\n",
    "    LESS = \"<\"\n",
    "    LESSEQUAL = \"<=\"\n",
    "    MORE = \">\"\n",
    "    MOREEQUAL = \">=\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._value_\n",
    "\n",
    "\n",
    "class CategoricalOperator(str, Enum):\n",
    "    IN = \"in\"\n",
    "    NOTIN = \"not in\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._value_\n",
    "\n",
    "\n",
    "class Filter(BaseModel):\n",
    "    col_name: StrictStr\n",
    "    operator: Union[GenericOperator, NumericalOperator, CategoricalOperator]\n",
    "    value: Union[\n",
    "        list[Union[StrictStr, StrictBool, StrictInt]],\n",
    "        StrictStr,\n",
    "        StrictInt,\n",
    "        StrictFloat,\n",
    "        StrictBool,\n",
    "    ]\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def check_passwords_match(self) -> 'Filter':\n",
    "        if type(self.operator) == NumericalOperator and type(self.value) not in [int, float]:\n",
    "            raise ValueError(f'Value ({self.value}) not allowed for numerical operator ({self.operator})')\n",
    "        elif type(self.operator) == CategoricalOperator and type(self.value) not in [list]:\n",
    "            raise ValueError(f'Value ({self.value}) not allowed for categorical operator ({self.operator})')\n",
    "        elif type(self.operator) == GenericOperator and type(self.value) in [list]:\n",
    "            raise ValueError(f'Value ({self.value}) not allowed for generic operator ({self.operator})')\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filter(col_name='nome_colonna', operator=<CategoricalOperator.IN: 'in'>, value=[4, 5])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Filter(\n",
    "    col_name=\"nome_colonna\",\n",
    "    operator=\"in\",\n",
    "    value=[4, 5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/10 16:54:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+-------+----------------+--------+\n",
      "|ID_BIC_CLIENTE|DATA_TRANSAZIONE|IMPORTO|CA_CATEGORY_LIV0|IS_CARTA|\n",
      "+--------------+----------------+-------+----------------+--------+\n",
      "|     348272371|      2023-01-01|    5.5|        shopping|    true|\n",
      "|     348272371|      2023-01-01|    6.1|          salute|   false|\n",
      "|     348272371|      2023-01-01|    8.2|       trasporti|   false|\n",
      "|     348272371|      2023-01-01|    1.5|       trasporti|    true|\n",
      "|     348272371|      2023-01-06|   20.2|        shopping|   false|\n",
      "|     348272371|      2023-01-06|   43.0|        shopping|    true|\n",
      "|     348272371|      2023-01-06|   72.2|        shopping|   false|\n",
      "|     234984832|      2023-01-01|  15.34|          salute|    true|\n",
      "|     234984832|      2023-01-01|  36.22|          salute|    true|\n",
      "|     234984832|      2023-01-01|  78.35|          salute|   false|\n",
      "|     234984832|      2023-01-02|    2.2|       trasporti|    true|\n",
      "+--------------+----------------+-------+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "        data=[\n",
    "            (348272371, \"2023-01-01\", 5.50, \"shopping\", True),\n",
    "            (348272371, \"2023-01-01\", 6.10, \"salute\", False),\n",
    "            (348272371, \"2023-01-01\", 8.20, \"trasporti\", False),\n",
    "            (348272371, \"2023-01-01\", 1.50, \"trasporti\", True),\n",
    "            (348272371, \"2023-01-06\", 20.20, \"shopping\", False),\n",
    "            (348272371, \"2023-01-06\", 43.00, \"shopping\", True),\n",
    "            (348272371, \"2023-01-06\", 72.20, \"shopping\", False),\n",
    "            (234984832, \"2023-01-01\", 15.34, \"salute\", True),\n",
    "            (234984832, \"2023-01-01\", 36.22, \"salute\", True),\n",
    "            (234984832, \"2023-01-01\", 78.35, \"salute\", False),\n",
    "            (234984832, \"2023-01-02\", 2.20, \"trasporti\", True),\n",
    "        ],\n",
    "        schema=[\n",
    "            \"ID_BIC_CLIENTE\",\n",
    "            \"DATA_TRANSAZIONE\",\n",
    "            \"IMPORTO\",\n",
    "            \"CA_CATEGORY_LIV0\",\n",
    "            \"IS_CARTA\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+-------+----------------+--------+\n",
      "|ID_BIC_CLIENTE|DATA_TRANSAZIONE|IMPORTO|CA_CATEGORY_LIV0|IS_CARTA|\n",
      "+--------------+----------------+-------+----------------+--------+\n",
      "|     348272371|      2023-01-01|    5.5|        shopping|    true|\n",
      "+--------------+----------------+-------+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(F.col(\"IMPORTO\") == 5.50).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filter(operator=<CategoricalOperator.IN: 'in'>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/10 16:54:59 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pydantic import model_validator\n",
    "\n",
    "class GenericOperator(str, Enum):\n",
    "    EQUAL = \"=\"\n",
    "    DOUBLEEQUAL = \"==\"\n",
    "    NOTEQUAL = \"!=\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._value_\n",
    "\n",
    "\n",
    "class NumericalOperator(str, Enum):\n",
    "    LESS = \"<\"\n",
    "    LESSEQUAL = \"<=\"\n",
    "    MORE = \">\"\n",
    "    MOREEQUAL = \">=\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._value_\n",
    "\n",
    "\n",
    "class CategoricalOperator(str, Enum):\n",
    "    IN = \"in\"\n",
    "    NOTIN = \"not in\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._value_\n",
    "\n",
    "\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, BeforeValidator, AfterValidator\n",
    "\n",
    "\n",
    "def parse_operator(operator_str: str) -> Union[GenericOperator, NumericalOperator, CategoricalOperator]:\n",
    "    for operator in [*GenericOperator, *NumericalOperator, *CategoricalOperator]:\n",
    "        if operator_str == operator.value:\n",
    "            return operator\n",
    "    raise ValueError(\"Operator not allowed\")\n",
    "\n",
    "@dataclass\n",
    "class Filter:\n",
    "    operator: Annotated[\n",
    "        str,\n",
    "        AfterValidator(lambda v: parse_operator(v)),\n",
    "    ]\n",
    "    \n",
    "\n",
    "Filter(\"in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transactionsanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
